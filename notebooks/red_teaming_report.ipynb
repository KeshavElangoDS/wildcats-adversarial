{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Red teaming on Krishnasai's attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report depicts the report on the FGSM attack from Krishnasai (Krishnasai Narayanan <kn490@scarletmail.rutgers.edu>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation of Adversarial Attack and Defense Performance**\n",
    "\n",
    "This report examines the effectiveness of adversarial attacks using the Fast Gradient Sign Method (FGSM) and the defense mechanism applied through an ensemble approach, including JPEG compression and spatial smoothing. The analysis is conducted using MobileNetV3SmallCNN_AdamW before and after augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Adversarial Attack: FGSM**\n",
    "\n",
    "- **Adversarial Attack Accuracy**: The attack was set with an accuracy of 50% in both pre-augmentation and post-augmentation scenarios.\n",
    "- **Effectiveness**: Prior to augmentation, the adversarial defense of the model against FGSM attacks was low, achieving only **6.25% defense accuracy**.\n",
    "\n",
    "\n",
    "### **2. Defense Mechanism: Ensemble of JPEG Compression and Spatial Smoothing**\n",
    "\n",
    "The defense approach focused on two primary techniques:\n",
    "1. **JPEG Compression**: A method to reduce high-frequency components often exploited by adversarial perturbations.\n",
    "2. **Spatial Smoothing**: Mitigates adversarial noise by applying filters to smooth pixel intensities.\n",
    "\n",
    "#### **Impact of Defense Mechanism**\n",
    "After incorporating these ensemble defense techniques:\n",
    "- The adversarial defense accuracy improved from **6.25% to 12.50%**.\n",
    "- Despite the increase, the model remains significantly vulnerable, with adversarial attack accuracy remaining constant at **50%**.\n",
    "\n",
    "\n",
    "### **3. Model Test Accuracy**\n",
    "\n",
    "The evaluation of test image accuracy highlights the model's performance across two scenarios:\n",
    "\n",
    "- **Original Images (No Attack)**: \n",
    "  - Pre-augmentation: **53.12% accuracy**.\n",
    "  - Post-augmentation: **43.75% accuracy**.\n",
    "  - **Insight**: Augmentation led to a decrease in original image classification accuracy, potentially due to the trade-off introduced by defensive adjustments.\n",
    "  \n",
    "- **Adversarial Images (With FGSM)**:\n",
    "  - Pre-augmentation: **6.25% accuracy**.\n",
    "  - Post-augmentation: **12.50% accuracy**.\n",
    "  - **Insight**: Defensive augmentation significantly improved robustness to adversarial attacks, doubling the accuracy on adversarial images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Insights and Recommendations**\n",
    "\n",
    "### **1. Attack Effectiveness**\n",
    "- The FGSM attack is highly effective, drastically reducing model accuracy on adversarial images to **6.25%** in the unprotected scenario.\n",
    "- The attack's consistency at **50% adversarial attack accuracy** suggests that stronger defenses are required for practical robustness.\n",
    "\n",
    "### **2. Defense Evaluation**\n",
    "- The ensemble of JPEG compression and spatial smoothing showed moderate improvement in adversarial defense accuracy from **6.25% to 12.50%**.\n",
    "- However, the drop in performance on original images after augmentation (from **53.12% to 43.75%**) indicates a trade-off between robustness and general accuracy. Further optimization is needed to balance these outcomes.\n",
    "\n",
    "### **3. Recommendations**\n",
    "- Explore advanced augmentation techniques that preserve accuracy on clean images while improving adversarial robustness.\n",
    "- Combine ensemble defense with adversarial training for a more comprehensive approach.\n",
    "- Evaluate additional defenses such as input denoising or adversarial detector mechanisms for increased robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Conclusion**\n",
    "The ensemble defense approach improved the model's resilience against adversarial FGSM attacks but introduced a trade-off in overall accuracy. For enhanced adversarial robustness, a combination of advanced training and defensive mechanisms should be implemented and optimized."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
